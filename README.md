# Web-urls ğŸ•¸ï¸

![Spider](https://img.shields.io/badge/spider-web%20crawler-green)

Web-urlsæ˜¯ä¸€ä¸ªPythonè„šæœ¬ï¼Œå…è®¸ä½ è¾“å…¥è®¿é—®æŒ‡å®šç½‘é¡µï¼Œæå–å…¶ä¸­çš„æ‰€æœ‰ URLï¼Œå¹¶å°†ç»“æœå¯¼å‡ºåˆ° Excel æ–‡ä»¶ä¸­ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ•·ï¸ è®¿é—®æŒ‡å®š URLï¼Œæå–æ‰€æœ‰é“¾æ¥
- ğŸ”„ ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç† URLï¼Œå¹¶è·å–ç½‘é¡µæ ‡é¢˜
- ğŸ“Š å°†ç»“æœå¯¼å‡ºåˆ° Excel æ–‡ä»¶ä¸­ï¼ŒåŒ…å«åºå·ã€URLã€ç½‘é¡µæ ‡é¢˜å’ŒåŸŸå

## ä½¿ç”¨æ–¹æ³•

1. ä½¿ç”¨ç»ˆç«¯è¿è¡Œä»£ç ã€‚
2. è¾“å…¥è¦è®¿é—®çš„ç›®æ ‡ URLã€‚
3. è„šæœ¬å°†ä½¿ç”¨ Edge æµè§ˆå™¨è¯·æ±‚å¤´è®¿é—®ç½‘é¡µï¼ˆå¯è‡ªè¡Œä¿®æ”¹ï¼‰ã€‚
4. æ‰€æœ‰æå–åˆ°çš„ URL å°†ä¼šåœ¨ Excel æ–‡ä»¶ä¸­ä¿å­˜ã€‚

```
bashCopy code
python weburls.py
```

## æ³¨æ„äº‹é¡¹

- è¯·ç¡®ä¿ä½ æœ‰è¶³å¤Ÿçš„ç½‘ç»œè®¿é—®æƒé™ã€‚
- è¯·æ³¨æ„ç½‘ç«™çš„ä½¿ç”¨æ”¿ç­–å’Œ robots.txtã€‚
- å¦‚æœå‡ºç°è®¿é—®è¶…æ—¶æˆ–å…¶ä»–å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å¹¶é‡è¯•ã€‚
- è®¾ç½®çº¿ç¨‹éƒ¨åˆ†è¯·æ ¹æ®è¿è¡Œæƒ…å†µè°ƒæ•´ï¼Œè¿‡é«˜çš„çº¿ç¨‹æ— æ³•æ­£å¸¸è·å–æ ‡é¢˜ã€‚

## æ„å¤–æƒ…å†µ

â“ä»£ç ä»¥åŠå¯¼å‡ºçš„Excelä¸­æç¤ºå­—ç¬¦å«æœ‰ä¸­æ–‡ï¼Œè‹¥æ‚¨çš„è®¡ç®—æœºä¸æ”¯æŒç®€ä½“ä¸­æ–‡ï¼Œè¯·è‡ªè¡Œä¿®æ”¹ä»£ç ä¸­çš„å­—ç¬¦ã€‚

â“å¯¼å‡ºçš„Excelä¸­çš„åºå·ä¸ä¼šè‡ªç„¶æ’åºï¼Œè¯·è‡ªè¡Œè°ƒæ•´ï¼Œè‹¥æ‚¨æœ‰è§£å†³åŠæ³•ï¼Œè¯·åé¦ˆç»™æˆ‘ï¼Œè°¢è°¢ã€‚

## ä½œè€…

- [Cairns](https://github.com/cairns666)

ğŸš€ æ„Ÿè°¢ä½¿ç”¨æˆ‘çš„ Web æ•°æ®çˆ¬å–å·¥å…·ï¼ä½¿ç”¨ä»£ç è¯·éµå®ˆå¼€æºå®ˆåˆ™ï¼Œæ¬¢è¿æå‡ºå»ºè®®å’Œè´¡çŒ®ä»£ç ã€‚



*****



# Web-urls

Web-urls is a Python script that allows you to input a specified webpage, extract all URLs from it, and export the results to an Excel file.

## Features

- ğŸ•·ï¸ Visit a specified URL and extract all links
- ğŸ”„ Process URLs using multiple threads and fetch webpage titles
- ğŸ“Š Export results to an Excel file, including index, URL, webpage title, and domain

## Usage

1. Run the code using the terminal.
2. Enter the target URL you want to visit.
3. The script will access the webpage using the Edge browser request header (modifiable).
4. All extracted URLs will be saved in an Excel file.

```
bash
python weburls.py
```



## Notes

- Ensure you have sufficient network access.
- Be mindful of the website's usage policies and robots.txt.
- In case of timeouts or other issues, check your network connection and retry.

## Caveats

â“ The code and exported Excel may contain Chinese characters. If your computer does not support Simplified Chinese, feel free to modify the characters in the code.

â“ The index in the exported Excel may not be naturally sorted. Adjust it manually, and if you have a solution, please provide feedback. Thank you!

## Author

- [Cairns](https://github.com/cairns666)

ğŸš€ Thank you for using my Web data crawling tool! Adhere to open-source principles when using the code.Suggestions and code contributions are welcome.
